{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852afd74",
   "metadata": {},
   "source": [
    "<img src=\"poet.jpeg\" alt=\"Drawing\" style=\"width: 400px;\"/> \n",
    "<h2><center>Arabic Poetry Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a0fa4d",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14ef58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Python libraries\n",
    "#Classic,data manipulation \n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score,accuracy_score\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import markovify\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from pyarabic.araby import strip_harakat\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from ar_wordcloud import ArabicWordCloud\n",
    "\n",
    "import pyarabic.arabrepr\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis  # don't skip this\n",
    "from tashaphyne.stemming import ArabicLightStemmer\n",
    "import seaborn as sns\n",
    "import pyarabic.araby as araby\n",
    "import pyarabic.number as number\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "\n",
    "from tqdm import tqdm\n",
    "import pyarabic.araby as araby\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b4340",
   "metadata": {},
   "source": [
    "# Read DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc27ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Arabic Poem Comprehensive Dataset (APCD).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:100000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dde4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b805f3",
   "metadata": {},
   "source": [
    "# EDA 1-1: Features viualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed58e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Generation = df['العصر'].value_counts().sort_values(ascending=False ).to_frame().reset_index()\n",
    "Most_Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f3619",
   "metadata": {},
   "outputs": [],
   "source": [
    "zlbl= get_display( arabic_reshaper.reshape('اكثر الاشعار كانت في عصر'))\n",
    "plt.figure(figsize=[8,4])\n",
    "plt.title(zlbl)\n",
    "df_tuple4 =list(zip(Most_Generation['index'],Most_Generation['العصر']))\n",
    "\n",
    "first_columns= [get_display( arabic_reshaper.reshape(x[0])) for x in df_tuple4]\n",
    "second_columns= [x[1] for x in df_tuple4]\n",
    "\n",
    "xlbl = get_display( arabic_reshaper.reshape('index'))\n",
    "ylbl = get_display( arabic_reshaper.reshape('العصر'))\n",
    "\n",
    "\n",
    "sns.barplot(x = second_columns ,y=first_columns,data=Most_Generation,color = \"DarkRed\");\n",
    "plt.xlabel(xlbl, fontdict=None, labelpad=None)\n",
    "plt.ylabel(ylbl, fontdict=None, labelpad=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e355a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_poet = df['الشاعر'].value_counts().sort_values(ascending=False ).to_frame().reset_index()\n",
    "count_poet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from bidi.algorithm import get_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arabic_reshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a0ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "zlbl= get_display( arabic_reshaper.reshape('أكثر القصائد للشعراء'))\n",
    "plt.figure(figsize=[11,11])\n",
    "plt.title(zlbl)\n",
    "df_tuple =list(zip(count_poet['index'],count_poet['الشاعر']))\n",
    "\n",
    "first_columns= [get_display( arabic_reshaper.reshape(x[0])) for x in df_tuple]\n",
    "second_columns= [x[1] for x in df_tuple]\n",
    "\n",
    "xlbl = get_display( arabic_reshaper.reshape('index'))\n",
    "ylbl = get_display( arabic_reshaper.reshape('الشاعر'))\n",
    "\n",
    "\n",
    "sns.barplot(x = second_columns ,y=first_columns,data=count_poet,color = \"DarkRed\");\n",
    "plt.xlabel(xlbl, fontdict=None, labelpad=None)\n",
    "plt.ylabel(ylbl, fontdict=None, labelpad=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99354d85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.الديوان.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e40781",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count_rhyme = df['القافية'].value_counts().sort_values(ascending=False ).to_frame().reset_index()\n",
    "count_rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zlbl= get_display( arabic_reshaper.reshape('ًاكثر القرافي تكرارا'))\n",
    "plt.figure(figsize=[11,11])\n",
    "plt.title(zlbl)\n",
    "df_tuple2 =list(zip(count_rhyme['index'],count_rhyme['القافية']))\n",
    "\n",
    "first_columns= [get_display( arabic_reshaper.reshape(x[0])) for x in df_tuple2]\n",
    "second_columns= [x[1] for x in df_tuple2]\n",
    "\n",
    "xlbl = get_display( arabic_reshaper.reshape('index'))\n",
    "ylbl = get_display( arabic_reshaper.reshape('القافية'))\n",
    "\n",
    "\n",
    "sns.barplot(x = second_columns ,y=first_columns,data=count_rhyme,color = \"DarkRed\");\n",
    "plt.xlabel(xlbl, fontdict=None, labelpad=None)\n",
    "plt.ylabel(ylbl, fontdict=None, labelpad=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1b43f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_poem_type = df['البحر'].value_counts().sort_values(ascending=False ).to_frame().reset_index()\n",
    "count_poem_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3012655b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zlbl= get_display( arabic_reshaper.reshape('اكثر بحور الشعر استخدماً'))\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.title(zlbl)\n",
    "df_tuple3 =list(zip(count_poem_type['index'],count_poem_type['البحر']))\n",
    "\n",
    "first_columns= [get_display( arabic_reshaper.reshape(x[0])) for x in df_tuple3]\n",
    "second_columns= [x[1] for x in df_tuple3]\n",
    "\n",
    "xlbl = get_display( arabic_reshaper.reshape('index'))\n",
    "ylbl = get_display( arabic_reshaper.reshape('البحر'))\n",
    "\n",
    "\n",
    "sns.barplot(x = second_columns ,y=first_columns,data=count_poem_type ,color = \"DarkRed\");\n",
    "plt.xlabel(xlbl, fontdict=None, labelpad=None)\n",
    "plt.ylabel(ylbl, fontdict=None, labelpad=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e45168",
   "metadata": {},
   "source": [
    "# EDA 1-2: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da2f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8923d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f28966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e425fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ba0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162aaff6",
   "metadata": {},
   "source": [
    "# EDA1-3: Text Preprocessing\n",
    "\n",
    "> Removing stop words\n",
    "\n",
    "> Tokenization: Words, ngrams\n",
    "\n",
    "> Stemming or Lemmatizations \n",
    "\n",
    "> Part of speech\n",
    "\n",
    "> Word corrections\n",
    "\n",
    "> NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take order smaller datafram = 100000\n",
    "df=df.iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8f667",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(15)\n",
    "df['poem_id']=df.index\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'العصر': 'Generation','الشاعر':'poet_name','الديوان':'divan','القافية':'rhyme','البحر':'poem_type','الشطر الايسر':'left_side','الشطر الايمن':'right_side','البيت':'verse'}, inplace=True)\n",
    "df = df.reindex(columns=['poem_id','Generation', 'poet_name', 'divan', 'rhyme', 'poem_type', 'left_side','right_side', 'verse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f7f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea7370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca256b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb008dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['poet_name']=='عمرو بنِ قُمَيئَة']\n",
    "df.poet_name.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5911c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rhyme.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec50f6e",
   "metadata": {},
   "source": [
    "أبيات القصيدة كلّها مَبنيّةً على تفعيلةٍ واحدةٍ تتبع لبحرٍ مُعيّنٍ من بحور الشّعر العربيّ.\n",
    "وبحور الشّعر ستّة عشر بحراً وهي:\n",
    "المُتدارَك، والمُتقارِب، والمُجتثّ، والمُقتَضَب، والمُضارِع، والخفيف، والمُنسرِح، والسّريع، والرَّمَل، والرَّجَز، والهَزَج، والكامل، والوافر، والبَسيط، والمَديد، والطّويل."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd561f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.poem_type.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2726fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.groupby('rhyme')['poet_name'].value_counts().sort_values(ascending=False)\n",
    "poet_rhyme =df.groupby('poet_name')['poem_type']\n",
    "poet_rhyme.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e25c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804478c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poet_rhyme = df.groupby(['poet_name','rhyme']).size().reset_index(name ='Count')\n",
    "print(poet_rhyme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9bae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9cb34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.poet_name.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221500b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b9475",
   "metadata": {},
   "source": [
    "# Classify each Poet name with his verses by using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad7812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = df.verse\n",
    "y = df.poet_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val,x_test,y_train_val,y_test = train_test_split(x,y, test_size=0.2, random_state= 30)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train_val,y_train_val, test_size=0.2, random_state= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72516d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a special character _\n",
    "x_train= x_train.apply(lambda x: re.sub(r'[_]+', '', x))\n",
    "x_val= x_val.apply(lambda x: re.sub(r'[_]+', '', x))\n",
    "\n",
    "# remove (non-arabic-alphabet)\n",
    "x_train= x_train.str.replace('[^ء-ي ]', '')\n",
    "x_val= x_val.str.replace('[^ء-ي ]', '')\n",
    "\n",
    "# replcae (أ,آ,إ) by (ا)\n",
    "x_train= x_train.apply(lambda x: re.sub('[أإآ]', 'ا', x))\n",
    "x_val= x_val.apply(lambda x: re.sub('[أإآ]', 'ا', x))\n",
    "\n",
    "# replace (ة) by (ه)\n",
    "x_train = x_train.apply(lambda x: re.sub('[ة]', 'ه', x))\n",
    "x_val = x_val.apply(lambda x: re.sub('[ة]', 'ه', x))\n",
    "\n",
    "# remove multi spaces\n",
    "x_train= x_train.apply(lambda x: re.sub(' +', ' ', x).strip())\n",
    "x_val= x_val.apply(lambda x: re.sub(' +', ' ', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations\n",
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "x_train = x_train.apply(lambda x: x.translate(str.maketrans('', '', punctuations_list)))\n",
    "x_test = x_test.apply(lambda x: x.translate(str.maketrans('', '', punctuations_list)))\n",
    "x_val = x_val.apply(lambda x: x.translate(str.maketrans('', '', punctuations_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c49a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deNoise(text):\n",
    "    noise = re.compile(\"\"\" ّ      | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(noise, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text preprocessing for y_value\n",
    "y_train = y_train.apply(lambda x: deNoise(x))\n",
    "y_test = y_test.apply(lambda x: deNoise(x))\n",
    "y_val= y_val.apply(lambda x: deNoise(x))\n",
    "\n",
    "#For train Set\n",
    "y_train= y_train.apply(lambda x: re.sub(r'[_]+', '', x))\n",
    "y_train= y_train.str.replace('[^ء-ي ]', '')\n",
    "y_train= y_train.apply(lambda x: re.sub('[أإآ]', 'ا', x))\n",
    "y_train = y_train.apply(lambda x: re.sub('[ة]', 'ه', x))\n",
    "y_train= y_train.apply(lambda x: re.sub(' +', ' ', x).strip())\n",
    "#For validation set\n",
    "y_val= y_val.apply(lambda x: re.sub(r'[_]+', '', x))\n",
    "y_val= y_val.str.replace('[^ء-ي ]', '')\n",
    "y_val= y_val.apply(lambda x: re.sub('[أإآ]', 'ا', x))\n",
    "y_val = y_val.apply(lambda x: re.sub('[ة]', 'ه', x))\n",
    "y_val= y_val.apply(lambda x: re.sub(' +', ' ', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('arabic')\n",
    "stop_words.extend(['هـ', 'د', 'م', 'الى', 'ان', 'اذ', 'لهذه', 'قال', 'وقال', 'اكد', 'عدد', 'بعدد', 'وعدد'\n",
    "                  , 'والتي', 'بن', 'بنت', 'وقد', 'ا', 'عبر', 'خلال', 'او', 'الا', 'وان', 'اي', 'بان', 'كان'\n",
    "                  , 'كانت' ,'تم','الف','مليون', 'وفي', 'وقد','اكثر','اقل', 'انه','وانه', 'قالت', 'وقالت', 'وتم'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first document-term matrix has default Count Vectorizer values - counts of unigrams\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv1 = CountVectorizer(stop_words='arabic')\n",
    "\n",
    "x_train_cv1 = cv1.fit_transform(x_train)\n",
    "x_test_cv1  = cv1.transform(x_val)\n",
    "\n",
    "pd.DataFrame(x_train_cv1.toarray(), columns=cv1.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1c578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63bd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d37b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc9fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110eafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f050e71",
   "metadata": {},
   "source": [
    "# NLP -Unsupervised ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train =x_train['verse'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(stopwords.words('arabic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bfb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f1968c",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2331b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentence Tokenization\n",
    "data = list(df['verse'].tolist())\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f53d78",
   "metadata": {},
   "source": [
    "# Stop words removal & Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('arabic')\n",
    "stop_words.extend(['هـ', 'د', 'م', 'الى', 'ان', 'اذ', 'لهذه', 'قال', 'وقال', 'اكد', 'عدد', 'بعدد', 'وعدد'\n",
    "                  , 'والتي', 'بن', 'بنت', 'وقد', 'ا', 'عبر', 'خلال', 'او', 'الا', 'وان', 'اي', 'بان', 'كان'\n",
    "                  , 'كانت' ,'تم','الف','مليون', 'وفي', 'وقد','اكثر','اقل', 'انه','وانه', 'قالت', 'وقالت', 'وتم'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efff216",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stpwrd=remove_stopwords(text)\n",
    "remove_stpwrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a07221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming as experiment\n",
    "def apply_stemming_and_Stopwords(texts):\n",
    "    st = ISRIStemmer()\n",
    "    return [[st.stem(word) for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4028d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmstop_word=apply_stemming_and_Stopwords(text)\n",
    "stemmstop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    " \n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b154ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_words_nostops = apply_stemming_and_Stopwords(data_words)\n",
    "data_words_nostops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a923e74",
   "metadata": {},
   "outputs": [],
   "source": [
    " def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a6f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(remove_stpwrd)\n",
    "data_words_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c797ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_trigrams = make_trigrams(data_words_bigrams)\n",
    "data_words_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams  = (df['verse'].str.replace(r'[^a-z\\s]', '').str.split(expand=True).stac\n",
    "\n",
    "# generate bigrams by concatenating unigram columns\n",
    "bigrams = unigrams + ' ' + unigrams.shift(-1)\n",
    "# generate trigrams by concatenating unigram and bigram columns\n",
    "trigrams = bigrams + ' ' + unigrams.shift(-2)\n",
    "\n",
    "# concatenate all series vertically, and remove NaNs\n",
    "txt_ngram=pd.concat([unigrams, bigrams, trigrams]).dropna().reset_index(drop=True)\n",
    "txt_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7a2288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e07327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2aacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44d7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa83c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = ['ض', 'ص', 'ث', 'ق', 'ف', 'غ', 'ع', 'ه', 'خ', 'ح', 'ج', 'د', 'ش', 'س', 'ي', 'ب', 'ل', 'ا', 'ت', 'ن', 'م',\n",
    "                 'ك', 'ط', 'ئ', 'ء', 'ؤ', 'ر' , 'ى', 'ة', 'و', 'ز', 'ظ', 'إ' ,'أ', 'آ', ' ', '\\n', 'ذ', 'ّ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2377bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_puncs(poem):\n",
    "    for l in poem:\n",
    "        if l not in allowed_chars:\n",
    "            poem = poem.replace(l, \"\")\n",
    "            return poem\n",
    "\n",
    "def extract_poems(poet_name):\n",
    "    with open('all_poems.csv'.format(poet_name), 'w', encoding=\"utf-8\") as f:\n",
    "        for i in range(len(df)):\n",
    "            if df['poet_name'][i].format(poet_name) == poet_name:\n",
    "                poem = delete_puncs(df['verse'][i])\n",
    "                f.write(\"{}\\n\\n\".format(poem)).verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f22421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['rhyme'][257]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ad30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_poets = set()\n",
    "for poet_name in df['verse']:\n",
    "    all_poets.add(poet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d4e10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "after_filter = araby.strip_diacritics(text)\n",
    "\n",
    "print(after_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all words on the same rythmes\n",
    "\n",
    "def rhymes_with(word):\n",
    "    if word not in ['الله', 'والله', 'بالله', 'لله', 'تالله']:\n",
    "        word = word.replace('ّ', '')\n",
    "    ending = word[-2:]\n",
    "    rhymes = []\n",
    "    for w in voc_list:\n",
    "        if len(w) < max_word_length and w.endswith(ending):\n",
    "            rhymes.append(w)\n",
    "    return rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6daf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhymes_with_last_n_chars(word, n):\n",
    "    if word not in ['الله', 'والله', 'بالله', 'لله', 'تالله', 'فالله']:\n",
    "        word = word.replace('ّ', '')\n",
    "        ending = word[-n:]\n",
    "        rhymes = []\n",
    "        for w in voc_list:\n",
    "            if len(w) < max_word_length and w.endswith(ending):\n",
    "                rhymes.append(w)\n",
    "                return rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595bc96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_poems= df['poet_name'].apply(lambda text,x: rhymes_with_last_n_chars(text,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('vocabs.pkl', 'rb') as pickle_load:\n",
    "    voc_list = pickle.load(pickle_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "from tqdm import tqdm\n",
    "\n",
    "def markov(text_file):\n",
    "    with open(text_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text_model = markovify.NewlineText(text)\n",
    "    return text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1ec0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_poem_single_rhyme(poet_name, rhyme, iterations=3000, use_tqdm=False):\n",
    "    n_of_rhyme_letters = len(rhyme)\n",
    "    input_ff =  df.loc[df['poet_name'] == poet_name]\n",
    "    input_file = '../input/poem-txt/.txt'\n",
    "    text_model = markov(input_file)\n",
    "    rhymes_list = rhymes_with_last_n_chars(rhyme, n_of_rhyme_letters)\n",
    "    bayts = set()\n",
    "    used_rhymes = set()\n",
    "    \n",
    "    poem = \"\"\n",
    "    \n",
    "    if use_tqdm == True:\n",
    "        if hasattr(tqdm, '_instances'): tqdm._instances.clear()\n",
    "        it_range = tqdm(range(iterations))\n",
    "    else:\n",
    "        it_range = range(iterations)\n",
    "        \n",
    "    for i in it_range:\n",
    "        bayt = text_model.make_short_sentence(280, tries=100)\n",
    "        last_word = bayt.split()[-1]\n",
    "        if (last_word in rhymes_list) and (last_word not in used_rhymes) and (bayt not in bayts):\n",
    "            bayts.add(bayt)\n",
    "            used_rhymes.add(last_word)\n",
    "            poem += \"{}\\n\".format(bayt)\n",
    "            if not use_tqdm:\n",
    "                print(bayt)\n",
    "    return poem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18cc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem_2_rhymes(poet_name, rhyme_1, rhyme_2, iterations=3000, use_tqdm=False):\n",
    "    n_of_rhyme_1_letters = len(rhyme_1)\n",
    "    n_of_rhyme_2_letters = len(rhyme_2)\n",
    "    \n",
    "    input_ff =  df.loc[df['poet_name'] == poet_name]\n",
    "    input_file = '../input/poem-txt/.txt'\n",
    "    text_model = markov(input_file)\n",
    "    \n",
    "    rhymes_1_list = rhymes_with_last_n_chars(rhyme_1, n_of_rhyme_1_letters)\n",
    "    rhymes_2_list = rhymes_with_last_n_chars(rhyme_2, n_of_rhyme_2_letters)\n",
    "    \n",
    "    bayts_1 = set()\n",
    "    bayts_2 = set()\n",
    "    \n",
    "    used_rhymes_1 = set()\n",
    "    used_rhymes_2 = set()\n",
    "    \n",
    "    poem = \"\"\n",
    "    \n",
    "    if use_tqdm == True:\n",
    "        if hasattr(tqdm, '_instances'): tqdm._instances.clear()\n",
    "        it_range = tqdm(range(iterations))\n",
    "    else:\n",
    "        it_range = range(iterations)\n",
    "        \n",
    "    for i in it_range:\n",
    "        bayt = text_model.make_short_sentence(280, tries=100)\n",
    "        last_word = bayt.split()[-1]\n",
    "        \n",
    "        if (last_word in rhymes_1_list) and (last_word not in used_rhymes_1) and (bayt not in bayts_1):\n",
    "            bayts_1.add(bayt)\n",
    "            used_rhymes_1.add(last_word)\n",
    "\n",
    "        if (last_word in rhymes_2_list) and (last_word not in used_rhymes_2) and (bayt not in bayts_2):\n",
    "            bayts_2.add(bayt)\n",
    "            used_rhymes_2.add(last_word)                \n",
    "    \n",
    "    len_of_poem = min(len(bayts_1), len(bayts_2))\n",
    "    for i in range(len_of_poem):\n",
    "        poem += \"{}\\n{}\\n\".format(list(bayts_1)[i], list(bayts_2)[i])\n",
    "        \n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69758f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = generate_poem_single_rhyme('ب','الأَخطَل', iterations=3000, use_tqdm=False)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b66e0",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the document-term matrix \n",
    "arb_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "tfidf = TfidfVectorizer(stop_words=arb_stopwords)\n",
    "doc_words = tfidf.fit_transform(df.verse)\n",
    "tfidf_feature_name=pd.DataFrame(doc_words.toarray(),columns=tfidf.get_feature_names())\n",
    "tfidf_feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ba55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "?ArabicWordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81793a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "font_file = './NotoNaskhArabic-Regular.ttf'\n",
    "wordcloud = WordCloud(width = 800, height = 800,min_font_size = 10,font_path=font_file).generate(doc_words)\n",
    "wordcloud.to_file(\"arabic_example13.png\")\n",
    "#<wordcloud.wordcloud.WordCloud at 0x1ca1b4a9550>\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800973e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "?ArabicWordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940fa484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print WordCloud visualization\n",
    "\n",
    "awc = ArabicWordCloud(background_color=\"black\")\n",
    "\n",
    "mpl.rcParams['figure.figsize']=(20,12.0)  \n",
    "mpl.rcParams['font.size']=12            \n",
    "mpl.rcParams['savefig.dpi']=100             \n",
    "mpl.rcParams['figure.subplot.bottom']=.1 \n",
    "mpl.rcParams['figure.file']='NotoSansArabic-ExtraBold.ttf'\n",
    "\n",
    "# wordcloud = awc.generate(str(tfidf.get_feature_names())).from_text(\n",
    "#     str(tfidf.get_feature_names()))`\n",
    "\n",
    "wordcloud = awc.generate(str(tfidf.get_feature_names())).from_text(str(tfidf.get_feature_names()))\n",
    "\n",
    "print(wordcloud)\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud.recolor(colormap='Dark2'),interpolation='bilinear')\n",
    "#plt.title(\"Word Cloud of all the words\")\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfa2e4",
   "metadata": {},
   "source": [
    "# K-mean Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "?TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7105ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb420e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.verse.copy()\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=arb_stopwords, max_df=8, min_df=2)\n",
    "X = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a3e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4f152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_k = 8\n",
    "# model = KMeans(n_clusters=true_k, init='k-means++',random_state=60, max_iter=100, n_init=1)\n",
    "model = KMeans(n_clusters=true_k, init='k-means++',random_state=60, max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
